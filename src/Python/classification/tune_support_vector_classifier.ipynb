{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\git\\MachineLearning\\Project\\InteractionsClassification\\src\\classification\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\src\\classification\n",
      "C:\\Users\\luisp\\AppData\\Local\\Programs\\Python\\Python37\\python37.zip\n",
      "C:\\Users\\luisp\\AppData\\Local\\Programs\\Python\\Python37\\DLLs\n",
      "C:\\Users\\luisp\\AppData\\Local\\Programs\\Python\\Python37\\lib\n",
      "C:\\Users\\luisp\\AppData\\Local\\Programs\\Python\\Python37\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\venv\n",
      "\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\venv\\lib\\site-packages\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\venv\\lib\\site-packages\\setuptools-40.8.0-py3.7.egg\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\venv\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\luisp\\.ipython\n",
      "C:\\git\\MachineLearning\\Project\\InteractionsClassification\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd().replace(f\"\\classification\", \"\"))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration READY\n",
      "Creating dataset from STRING...\n",
      "Creating features...\n",
      "Features READY\n",
      "Creating targets...\n",
      "Reading Reactome unique interactions...\n",
      "Reactome interactions READY\n",
      "Added index to targets.\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import config_loader\n",
    "from dataset import dataset_loader\n",
    "\n",
    "dataset = dataset_loader.load_dataset(config_loader.read_config('../../'))\n",
    "\n",
    "# %% Create test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_sample, X_discard, y_sample, y_discard = train_test_split(dataset['features'], dataset['targets'], random_state=33,\n",
    "                                                            test_size=0.7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, random_state=33, test_size=0.2)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (InteractionsClassification)",
   "language": "python",
   "name": "pycharm-c08ea610"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
